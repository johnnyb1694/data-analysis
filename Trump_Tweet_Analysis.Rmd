---
title: "Analysis of Trump Tweets"
author: "Johnny Breen"
date: "05/03/2019"
output: html_document
---

### Introduction

The data that I have chosen to analyse in this document is a repository of Trump tweets which span roughly two years of data all the way up until Trump's election as US president in November 2016. The original CSV file I have used in the following analysis can be found [here](https://www.kaggle.com/kingburrito666/better-donald-trump-tweets) on Kaggle.

### Credits

My analysis of Trump's tweets draws a substantial amount of insight from David Robinson's recent screencast where he analysed a repository of medium articles - that specific screencast can be found [here](https://www.youtube.com/watch?v=C69QyycHsgE) and I highly encourage anyone interested in text mining to watch it at their next available moment.

### Plan

I have outlined below the main tasks that need to be performed in order to create a simple text mining model which can be fit to the data:

* Read in the data
* Preprocess the data
* Explore the data (attempt to perform sentiment & word correlation analyses)
* Apply a machine learning model to predict the number of retweets, based on the contents of a given tweet

We would like to create a model that can take a given input tweet and assign to that tweet the predicted number of retweets based on its contents. This type of task may (with large caveats of course!) be useful for a business looking to improve their social media presence.

## Preliminaries

The first step is to load any necessary packages and read in the data:

```{r warning=FALSE, message=FALSE}
load_req_packages <- function (req_libraries = c("tidyverse", "magrittr", "broom", "widyr", "ggraph", "igraph")) {
  for (req_lib in req_libraries) {
    if (!(req_lib %in% installed.packages())) {
      install.packages(req_lib)
    }
  }
  sapply(req_libraries, require, character.only = TRUE)
}

load_req_packages() # runs the function defined above
```

To read in CSV data, I will make use of the `readr::read_csv()` function: 

```{r warning=FALSE, message=FALSE}
proj_root <- "~/Desktop/Data Science/R/Project Trump/" 
trump_tweets_raw <- read_csv(file = paste0(proj_root, "Data/Trump_Tweets.csv"))
```

## Pre-processing

Before we pre-process the data, we can inspect the first 10 rows of the data using the `head()` function:

```{r}
 trump_tweets_raw %>%
    head()
```

# Questions to Ponder

Straight off the bat we have a few preliminary data-based questions:

1. Are the missing values in the `Media_Type` and `Hashtags` MCAR ("Missing Completely At Random") or MNAR ("Missing Not At Random")? In other words, do they actually 
2. Is the `Tweet_Id` useful at all? Why does it appear to be populated with a static value of `7.97e17`?
3. What are `X11` and `X12`? Are they completely missing? They seem to stem from a parsing error when using `read_csv()` but we should verify this by glancing at the documentation for the source data

We can solve question 3 by checking the documentation - this reveals that `X11` and `X12` are likely to be due to some parsing error. We can therefore remove them. Question 2 is not as clear-cut but it does not appear to be informative so we will drop it as well.

As for question 1, I will make the assumption that `NA` indicates that either no photo was attached (in the case of `Media_Type`) or that no hashtag exists (in the case of `Hashtags`).

# Pre-processing Tasks

We now have a series of clear pre-processing tasks to follow:

1. Remove redundant columns
2. Rename columns 
3. Impute missing values on 'Media_Type' and 'Hashtags' variables
4. Convert the relevant variables to factors
5. Separate dates and times into different columns
6. Remove link quotations in the 'Tweet_Text' field

```{r}
# define which columns we would like to remove, rename and convert into factors
cols_to_remove <- c("X11", "X12", "Tweet_Id", "Tweet_Url")
cols_to_rename <- c(Tweet = "Tweet_Text", Likes = "twt_favourites_IS_THIS_LIKE_QUESTION_MARK")
cols_to_fct <- c("Type", "Media_Type", "Hashtags")

# define a simple function which can take, as input, the columns to turn into factors and output the corrected dataframe
to_factor <- function (df, cols_to_fct) {
  df[cols_to_fct] <- map_dfr(df[cols_to_fct], factor) %>%
    as_tibble()
  return(df)
}

trump_tweets_clean <- trump_tweets_raw %>%
  select(-cols_to_remove) %>% 
  rename(!!cols_to_rename) %>% # since dplyr quotes its inputs, by default, we need to communicate that we have already done this (i.e. we don't want 'rename' to take 'cols_to_rename' too literally...) by using '!!'
  replace_na(list(Media_Type = "(None)", Hashtags = "(None)")) %>%
  to_factor(cols_to_fct) %>% 
  separate(col = Date, into = c("Year", "Month", "Day"), sep = "-", convert = TRUE) %>% 
  separate(col = Time, into = c("Hour", "Minute", "Second"), sep = ":", convert = TRUE) %>% 
  mutate(Hour_Min = Hour + Minute / 60) %>% 
  select(-Minute, -Second) %>% 
  mutate(Tweet = str_replace_all(Tweet, "(www|http:|https:)+[^\\s]+", "")) %>% # remove links
  mutate(Tweet = str_replace_all(Tweet, "\\d+\\:\\d+", "")) 

trump_tweets_clean %>%
    head()
```

## Data Exploration